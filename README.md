# Crypto_Ai
# 1. í”„ë¡œì íŠ¸ í´ë” ìƒì„± ë° vs code ì—´ê¸°
```
mkdir crypto_pullback_ai
cd crypto_pullback_ai
code .
```
# 2. vs code í„°ë¯¸ë„ì—ì„œ conda í™˜ê²½ ì„¤ì • ë° ìƒì„±
```
conda create -n crypto_pullback_ai python=3.9
conda activate crypto_pullback_ai 
```
# 3. ìµœì í™”ëœ í”„ë¡œì íŠ¸ êµ¬ì¡° ë§Œë“¤ê¸°
<img width="516" alt="image" src="https://github.com/user-attachments/assets/ad774d93-078a-4c2e-9d7e-d28ff9821866" />


```
cat > setup_project.sh << 'EOF'
#!/bin/bash
mkdir -p {data/{processed,raw,exports},src,notebooks,tests,config,models/{saved_models,configs},sql}
touch main.py requirements.txt .env .gitignore README.md
touch src/{__init__.py,data_collector.py,database_manager.py,models.py,utils.py}
touch notebooks/{01_data_exploration.ipynb,02_model_development.ipynb,03_backtesting.ipynb,04_results_analysis.ipynb}
touch tests/{test_data.py,test_models.py}
touch config/{database.py,settings.py}
touch sql/{create_tables.sql,sample_queries.sql}
echo "í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„± ì™„ë£Œ!"
EOF

chmod +x setup_project.sh
./setup_project.sh
```

# 4. colab ì‚¬ìš©ì‹œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì „ëµ
## (1)vs code ì„¤ì¹˜
```
### ë°ì´í„° ìˆ˜ì§‘ ë° PostgreSQL ê´€ë ¨ (ë¡œì»¬ì—ì„œë§Œ ì‚¬ìš©)
conda install pandas numpy matplotlib seaborn # ë°ì´í„° ë¶„ì„ ë° ì²˜ë¦¬ # ìˆ˜ì¹˜ ê³„ì‚° # ê·¸ë˜í”„ ìƒì„± # ê³ ê¸‰ ì‹œê°í™”
pip install ccxt python-binance psycopg2-binary sqlalchemy python-dotenv # ê±°ë˜ì†Œ API í†µí•© # ë°”ì´ë‚¸ìŠ¤ ì „ìš© API # PostgreSQL ì—°ê²° # ORM (ë°ì´í„°ë² ì´ìŠ¤ ì¶”ìƒí™”) # .env íŒŒì¼ ì½ê¸° # ì‘ì—… ìŠ¤ì¼€ì¤„ë§ # ì§„í–‰ë¥  í‘œì‹œ
``` 
## (2) colab ì„¤ì¹˜
```
### ê° Colab ë…¸íŠ¸ë¶ ì²« ë²ˆì§¸ ì…€ì—ì„œ
!pip install ccxt python-binance psycopg2-binary sqlalchemy
!pip install optuna scikit-optimize
!pip install ta-lib  # ê¸°ìˆ ì  ì§€í‘œ ë¼ì´ë¸ŒëŸ¬ë¦¬
# ì´ë¯¸ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ë“¤ (Colab ê¸°ë³¸ ì œê³µ)
# - pandas, numpy, matplotlib, seaborn
# - jupyter, tensorflow, scikit-learn
```
# 5. í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ì„¤ì •
### .env íŒŒì¼ ë‚´ìš©(code .env)
```
# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=crypto_research
DB_USER=postgres
DB_PASSWORD=your_password_here

# Binance API (ë‚˜ì¤‘ì— ì‹¤ê±°ë˜ìš©)
BINANCE_API_KEY=
BINANCE_API_SECRET=

# Application Settings
LOG_LEVEL=INFO
DATA_UPDATE_INTERVAL=300  # 5ë¶„
```
# 6. ê¸°ë³¸ì„¤ì • íŒŒì¼ ì‘ì„±
### config/settings.py ë‚´ìš©(code config/settings.py)
```
"""
ê¸°ë³¸ ì„¤ì • íŒŒì¼
"""
import os
from dotenv import load_dotenv

load_dotenv()

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
DATABASE_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': int(os.getenv('DB_PORT', 5432)),
    'database': os.getenv('DB_NAME', 'crypto_research'),
    'user': os.getenv('DB_USER', 'postgres'),
    'password': os.getenv('DB_PASSWORD', '')
}

# ë°”ì´ë‚¸ìŠ¤ API ì„¤ì •
BINANCE_CONFIG = {
    'api_key': os.getenv('BINANCE_API_KEY', ''),
    'api_secret': os.getenv('BINANCE_API_SECRET', '')
}

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
APP_CONFIG = {
    'log_level': os.getenv('LOG_LEVEL', 'INFO'),
    'data_update_interval': int(os.getenv('DATA_UPDATE_INTERVAL', 300))
}

# ê±°ë˜ ì„¤ì •
TRADING_CONFIG = {
    'symbols': ['BTC/USDT', 'ETH/USDT'],
    'timeframe': '5m',
    'max_position_size': 0.1,  # 10%
    'stop_loss': -0.01,        # -1%
    'take_profit': 0.02        # 2%
}
```
# 7. ë°ì´í„° ìˆ˜ì§‘ê¸° ì™„ì„±
### src/data_collector.py ë‚´ìš©(code src/data_collector.py)
```
"""
ë°”ì´ë‚¸ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ê¸°
"""
import ccxt
import pandas as pd
import time
import logging
from datetime import datetime, timedelta
from typing import Optional, List
from config.settings import BINANCE_CONFIG, TRADING_CONFIG
from tqdm import tqdm

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class BinanceDataCollector:
    """ë°”ì´ë‚¸ìŠ¤ ì„ ë¬¼ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.exchange = ccxt.binance({
            'apiKey': BINANCE_CONFIG['api_key'],
            'secret': BINANCE_CONFIG['api_secret'],
            'sandbox': False,
            'rateLimit': 1200,
            'enableRateLimit': True,
            'options': {
                'defaultType': 'future',
            }
        })
        
        logger.info("ë°”ì´ë‚¸ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def test_connection(self) -> bool:
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            markets = self.exchange.load_markets()
            ticker = self.exchange.fetch_ticker('BTC/USDT')
            logger.info(f"ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ - BTC í˜„ì¬ê°€: ${ticker['last']:,.2f}")
            return True
        except Exception as e:
            logger.error(f"ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def collect_historical_data(self, symbol: str, days: int = 30) -> pd.DataFrame:
        """ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘"""
        logger.info(f"{symbol} ê³¼ê±° {days}ì¼ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        
        try:
            # ìˆ˜ì§‘í•  ë°ì´í„° ê³„ì‚°
            total_candles = days * 24 * 12  # 5ë¶„ë´‰ ê¸°ì¤€
            batches = (total_candles // 1000) + 1
            
            all_data = []
            
            for batch in tqdm(range(batches), desc=f"{symbol} ë°ì´í„° ìˆ˜ì§‘"):
                try:
                    # ì‹œì‘ ì‹œê°„ ê³„ì‚°
                    since = int((datetime.now() - timedelta(days=days) + timedelta(minutes=batch*1000*5)).timestamp() * 1000)
                    
                    # ë°ì´í„° ìš”ì²­
                    ohlcv = self.exchange.fetch_ohlcv(
                        symbol=symbol,
                        timeframe='5m',
                        since=since,
                        limit=1000
                    )
                    
                    if ohlcv:
                        all_data.extend(ohlcv)
                    
                    # API ì œí•œ ì¤€ìˆ˜
                    time.sleep(0.1)
                    
                except Exception as e:
                    logger.warning(f"ë°°ì¹˜ {batch} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
            if all_data:
                # DataFrame ìƒì„±
                df = pd.DataFrame(all_data, columns=[
                    'timestamp', 'open', 'high', 'low', 'close', 'volume'
                ])
                
                # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
                df = df.drop_duplicates(subset=['timestamp']).sort_values('timestamp')
                
                # ì‹œê°„ ë³€í™˜
                df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
                df['symbol'] = symbol
                
                logger.info(f"{symbol} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(df)}ê°œ ìº”ë“¤")
                return df
            else:
                logger.warning(f"{symbol} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"{symbol} ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            return pd.DataFrame()
    
    def get_current_price(self, symbol: str) -> float:
        """í˜„ì¬ ê°€ê²© ì¡°íšŒ"""
        try:
            ticker = self.exchange.fetch_ticker(symbol)
            return ticker['last']
        except Exception as e:
            logger.error(f"{symbol} í˜„ì¬ ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0.0

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    collector = BinanceDataCollector()
    
    if collector.test_connection():
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘
        df = collector.collect_historical_data('BTC/USDT', days=1)
        if not df.empty:
            print(f"âœ… ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ: {len(df)}ê°œ ìº”ë“¤")
            print(df.head())
            print(f"ê¸°ê°„: {df['datetime'].min()} ~ {df['datetime'].max()}")
        else:
            print("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
    else:
        print("âŒ ì—°ê²° ì‹¤íŒ¨")
```
# 8. ì²« ë²ˆì§¸ ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
```
# ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
python src/data_collector.py
```

# 9.PostgreSQL ì—°ê²° ì¤€ë¹„
### config/database.py ë‚´ìš©(code config/database.py)
```
"""
PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
"""
import psycopg2
from sqlalchemy import create_engine
from config.settings import DATABASE_CONFIG
import logging

logger = logging.getLogger(__name__)

def get_database_url():
    """ë°ì´í„°ë² ì´ìŠ¤ URL ìƒì„±"""
    return f"postgresql://{DATABASE_CONFIG['user']}:{DATABASE_CONFIG['password']}@{DATABASE_CONFIG['host']}:{DATABASE_CONFIG['port']}/{DATABASE_CONFIG['database']}"

def test_database_connection():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        conn = psycopg2.connect(
            host=DATABASE_CONFIG['host'],
            port=DATABASE_CONFIG['port'],
            database=DATABASE_CONFIG['database'],
            user=DATABASE_CONFIG['user'],
            password=DATABASE_CONFIG['password']
        )
        conn.close()
        logger.info("PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        return True
    except Exception as e:
        logger.error(f"PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def get_engine():
    """SQLAlchemy ì—”ì§„ ìƒì„±"""
    return create_engine(get_database_url())
```
# 10. ë©”ì¸ ì‹¤í–‰ íŒŒì¼ ì—…ë°ì´íŠ¸
### main.py ë‚´ìš©(code main.py)
```
"""
ë©”ì¸ ì‹¤í–‰ íŒŒì¼
"""
import sys
import os
import logging
from datetime import datetime

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.data_collector import BinanceDataCollector
from config.database import test_database_connection
from config.settings import TRADING_CONFIG

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Crypto Pullback AI ì‹œìŠ¤í…œ ì‹œì‘!")
    print("=" * 50)
    
    # 1. í™˜ê²½ í™•ì¸
    logger.info("ì‹œìŠ¤í…œ í™˜ê²½ í™•ì¸ ì¤‘...")
    
    # 2. ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    collector = BinanceDataCollector()
    
    # 3. ë°”ì´ë‚¸ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
    if not collector.test_connection():
        logger.error("ë°”ì´ë‚¸ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
        return
    
    # 4. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
    logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸...")
    if test_database_connection():
        logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
    else:
        logger.warning("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ - ë‚˜ì¤‘ì— ì„¤ì • í•„ìš”")
    
    # 5. ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘
    symbols = TRADING_CONFIG['symbols']
    
    print(f"\nğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ({len(symbols)}ê°œ ì‹¬ë³¼)")
    
    collected_data = {}
    
    for symbol in symbols:
        logger.info(f"{symbol} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        # 7ì¼ì¹˜ ë°ì´í„° ìˆ˜ì§‘
        df = collector.collect_historical_data(symbol, days=7)
        
        if not df.empty:
            collected_data[symbol] = df
            logger.info(f"âœ… {symbol} ì™„ë£Œ: {len(df)}ê°œ ìº”ë“¤")
            
            # ê°„ë‹¨í•œ í†µê³„ ì¶œë ¥
            current_price = df['close'].iloc[-1]
            price_change = ((current_price - df['close'].iloc[0]) / df['close'].iloc[0]) * 100
            
            print(f"   {symbol}: ${current_price:,.2f} ({price_change:+.2f}%)")
        else:
            logger.error(f"âŒ {symbol} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
    
    # 6. ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“ˆ ìˆ˜ì§‘ ì™„ë£Œ ìš”ì•½:")
    print(f"   ì„±ê³µ: {len(collected_data)}/{len(symbols)} ì‹¬ë³¼")
    print(f"   ì´ ë°ì´í„°: {sum(len(df) for df in collected_data.values())}ê°œ ìº”ë“¤")
    
    # 7. ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
    print(f"\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. PostgreSQL ì„¤ì • (ì„ íƒì‚¬í•­)")
    print("   2. ê¸°ë³¸ ë¶„ì„ ë° ì‹œê°í™”")
    print("   3. ëˆŒë¦¼ë§¤ë§¤ ì „ëµ ê°œë°œ")
    
    logger.info("0-1ë‹¨ê³„ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
```

# 11. ì²« ë²ˆì§¸ ì™„ì „ ì‹¤í–‰
```
# ì „ì²´ ì‹œìŠ¤í…œ ì‹¤í–‰
python main.py
```
